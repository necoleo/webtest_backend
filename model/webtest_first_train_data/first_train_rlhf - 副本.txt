run sh: `/home/ubuntu/webtest_rlhf_project/model_rlhf/bin/python3 /home/ubuntu/webtest_rlhf_project/model_rlhf/lib/python3.10/site-packages/swift/cli/rlhf.py --rlhf_type kto --model Qwen/Qwen-7B-Chat --train_type lora --dataset /home/ubuntu/webtest_rlhf_project/first_train_data/first_train_rlhf.jsonl --val_dataset /home/ubuntu/webtest_rlhf_project/first_train_data/first_dev_rlhf.jsonl --num_train_epochs 3 --per_device_train_batch_size 1 --per_device_eval_batch_size 1 --learning_rate 3e-5 --lora_rank 8 --lora_alpha 32 --target_modules all-linear --gradient_accumulation_steps 16 --eval_steps 3 --save_steps 3 --save_total_limit 5 --logging_steps 2 --max_length 4096 --output_dir first_rlhf_model_output --warmup_ratio 0.05 --dataloader_num_workers 4 --deepspeed zero3 --offload_optimizer true --offload_model true --gradient_checkpointing true`
[INFO:swift] Successfully registered `/home/ubuntu/webtest_rlhf_project/model_rlhf/lib/python3.10/site-packages/swift/llm/dataset/data/dataset_info.json`.
[INFO:swift] rank: -1, local_rank: -1, world_size: 1, local_world_size: 1
[INFO:swift] Downloading the model from ModelScope Hub, model_id: Qwen/Qwen-7B-Chat
[INFO:swift] Loading the model using model_dir: /home/ubuntu/.cache/modelscope/hub/models/Qwen/Qwen-7B-Chat
[INFO:swift] Setting torch_dtype: torch.bfloat16
[INFO:swift] Because len(args.val_dataset) > 0, setting split_dataset_ratio: 0.0
[INFO:swift] Setting args.lazy_tokenize: False
[INFO:swift] Using deepspeed: {'fp16': {'enabled': 'auto', 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': 'auto'}, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'none', 'pin_memory': True}, 'offload_param': {'device': 'none', 'pin_memory': True}, 'overlap_comm': False, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'zero_quantized_weights': False, 'zero_quantized_gradients': False, 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': 2000, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False}
[INFO:swift] output_dir: /home/ubuntu/webtest_rlhf_project/first_rlhf_model_output/v0-20251010-124038
[INFO:swift] Global seed set to 42
[INFO:swift] args: RLHFArguments(
_n_gpu=-1,
acc_strategy=token,
accelerator_config={'dispatch_batches': False},
adafactor=False,
adalora_beta1=0.85,
adalora_beta2=0.85,
adalora_deltaT=1,
adalora_init_r=12,
adalora_orth_reg_weight=0.5,
adalora_target_r=8,
adalora_tfinal=0,
adalora_tinit=0,
adam_beta1=0.9,
adam_beta2=0.95,
adam_epsilon=1e-08,
adapter_act=gelu,
adapter_length=128,
adapters=[],
add_version=True,
agent_template=None,
aligner_lr=None,
async_generate=False,
attn_impl=None,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
beta=0.1,
bf16=True,
bf16_full_eval=False,
bnb_4bit_compute_dtype=torch.bfloat16,
bnb_4bit_quant_storage=None,
bnb_4bit_quant_type=nf4,
bnb_4bit_use_double_quant=True,
boft_block_num=0,
boft_block_size=4,
boft_dropout=0.0,
boft_n_butterfly_factor=1,
cached_dataset=[],
center_rewards_coefficient=None,
channels=None,
check_model=True,
ckpt_dir=None,
cliprange=0.2,
cliprange_value=0.2,
columns={},
completion_length_limit_scope=per_round,
cosine_max_len=None,
cosine_max_len_value_correct=0.5,
cosine_max_len_value_wrong=0.0,
cosine_min_len_value_correct=1.0,
cosine_min_len_value_wrong=-0.5,
cpo_alpha=1.0,
create_checkpoint_symlink=False,
custom_dataset_info=[],
custom_register_path=[],
data_parallel_size=None,
data_seed=42,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
dataset=['/home/ubuntu/webtest_rlhf_project/first_train_data/first_train_rlhf.jsonl'],
dataset_num_proc=1,
dataset_shuffle=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=18000000,
debug=None,
deepspeed={'fp16': {'enabled': 'auto', 'loss_scale': 0, 'loss_scale_window': 1000, 'initial_scale_power': 16, 'hysteresis': 2, 'min_loss_scale': 1}, 'bf16': {'enabled': 'auto'}, 'zero_optimization': {'stage': 3, 'offload_optimizer': {'device': 'none', 'pin_memory': True}, 'offload_param': {'device': 'none', 'pin_memory': True}, 'overlap_comm': False, 'contiguous_gradients': True, 'sub_group_size': 1000000000.0, 'reduce_bucket_size': 'auto', 'zero_quantized_weights': False, 'zero_quantized_gradients': False, 'stage3_prefetch_bucket_size': 'auto', 'stage3_param_persistence_threshold': 'auto', 'stage3_max_live_parameters': 1000000000.0, 'stage3_max_reuse_distance': 1000000000.0, 'stage3_gather_16bit_weights_on_model_save': True}, 'gradient_accumulation_steps': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': 2000, 'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'wall_clock_breakdown': False},
deepspeed_autotp_size=None,
delta=None,
desirable_weight=1.0,
device_map=None,
disable_tqdm=None,
do_eval=False,
do_predict=False,
do_train=False,
download_mode=reuse_dataset_if_exists,
ds3_gather_for_generation=True,
dynamic_sample=False,
epsilon=0.2,
epsilon_high=None,
eval_accumulation_steps=None,
eval_dataset=[],
eval_dataset_args=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_generation_config=None,
eval_limit=None,
eval_on_start=False,
eval_steps=3.0,
eval_strategy=steps,
eval_use_evalscope=False,
eval_use_gather_object=False,
external_plugins=[],
fourier_n_frequency=2000,
fourier_scaling=300.0,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
freeze_aligner=True,
freeze_llm=False,
freeze_parameters=[],
freeze_parameters_ratio=0.0,
freeze_parameters_regex=None,
freeze_vit=True,
fsdp=,
fsdp_config=None,
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
galore_cos_threshold=0.4,
galore_gamma_proj=2,
galore_optim_per_parameter=False,
galore_proj_bits=4,
galore_proj_group_size=256,
galore_proj_quant=False,
galore_proj_type=std,
galore_quantization=False,
galore_queue_size=5,
galore_rank=128,
galore_scale=1.0,
galore_target_modules=None,
galore_update_proj_gap=50,
galore_with_embedding=False,
gamma=1.0,
gc_collect_after_offload=False,
generation_batch_size=None,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gpu_memory_utilization=None,
gradient_accumulation_steps=16,
gradient_checkpointing=True,
gradient_checkpointing_kwargs=None,
greater_is_better=False,
group_by_length=False,
half_precision_backend=auto,
hqq_axis=None,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_args_error=False,
ignore_data_skip=False,
importance_sampling_level=token,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
init_strategy=None,
init_weights=True,
interleave_prob=None,
jit_mode_eval=False,
kl_coef=0.05,
label_names=None,
label_smoothing=0,
label_smoothing_factor=0.0,
lam=0.95,
lazy_tokenize=False,
learning_rate=3e-05,
length_column_name=length,
liger_kernel_config=None,
limit_mm_per_prompt=None,
lisa_activated_layers=0,
lisa_step_interval=20,
llamapro_num_groups=None,
llamapro_num_new_blocks=4,
lmbda=0.5,
load_args=False,
load_best_model_at_end=False,
load_data_args=False,
load_from_cache_file=True,
local_rank=-1,
local_repo_path=None,
local_rollout_forward_batch_size=64,
log_completions=False,
log_entropy=False,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/ubuntu/webtest_rlhf_project/first_rlhf_model_output/v0-20251010-124038/runs,
logging_first_step=True,
logging_nan_inf_filter=True,
logging_steps=2,
logging_strategy=steps,
logprobs=False,
lora_alpha=32,
lora_bias=none,
lora_dropout=0.05,
lora_dtype=None,
lora_ga_batch_size=2,
lora_ga_direction=ArB2r,
lora_ga_iters=2,
lora_ga_max_length=1024,
lora_ga_scale=stable,
lora_ga_stable_gamma=16,
lora_modules=[],
lora_rank=8,
lorap_lr_ratio=None,
loss_scale=last_round,
loss_type=kto,
loss_weights=None,
lr_scheduler_kwargs=None,
lr_scheduler_type=cosine,
max_completion_length=512,
max_epochs=None,
max_grad_norm=1.0,
max_length=4096,
max_memory={},
max_model_len=None,
max_new_tokens=512,
max_pixels=None,
max_resample_times=3,
max_steps=-1,
max_turns=None,
metric=None,
metric_for_best_model=loss,
missing_eos_penalty=None,
model=Qwen/Qwen-7B-Chat,
model_author=None,
model_kwargs={},
model_name=None,
model_revision=None,
model_type=qwen,
modules_to_save=[],
move_model_batches=None,
mp_parameters=,
multi_turn_func=None,
multi_turn_scheduler=None,
neftune_noise_alpha=None,
new_special_tokens=[],
no_cuda=False,
norm_bbox=None,
num_beams=1,
num_generations=8,
num_iterations=1,
num_labels=None,
num_mini_batches=1,
num_ppo_epochs=4,
num_sample_generations=10,
num_train_epochs=3.0,
offload_model=True,
offload_optimizer=True,
optim=adamw_torch,
optim_args=None,
optim_target_modules=None,
optimizer=None,
output_dir=/home/ubuntu/webtest_rlhf_project/first_rlhf_model_output/v0-20251010-124038,
overlong_filter=False,
overwrite_output_dir=False,
packing=False,
padding_free=False,
padding_side=right,
past_index=-1,
per_device_eval_batch_size=1,
per_device_train_batch_size=1,
predict_with_generate=False,
prediction_loss_only=False,
problem_type=None,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
quant_bits=None,
quant_method=None,
ray_scope=last,
ref_model=None,
ref_model_mixup_alpha=0.6,
ref_model_revision=None,
ref_model_sync_steps=512,
ref_model_type=None,
reft_args=None,
reft_intervention_type=LoreftIntervention,
reft_layer_key=None,
reft_layers=None,
reft_rank=4,
remove_unused_columns=True,
repetition_max_penalty=-1.0,
repetition_n_grams=3,
repetition_penalty=1.0,
report_to=['tensorboard'],
response_length=512,
response_prefix=None,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
resume_only_model=False,
reward_adapters=[],
reward_funcs=[],
reward_model=None,
reward_model_plugin=None,
reward_model_revision=None,
reward_model_type=None,
reward_weights=None,
rlhf_type=kto,
rope_scaling=None,
router_aux_loss_coef=0.0,
rpo_alpha=1.0,
run_name=/home/ubuntu/webtest_rlhf_project/first_rlhf_model_output/v0-20251010-124038,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=3.0,
save_strategy=steps,
save_total_limit=5,
scale_rewards=True,
seed=42,
seq_kd=False,
sequence_parallel_size=1,
sft_alpha=0,
shuffle_buffer_size=1000,
simpo_gamma=1,
skip_memory_metrics=True,
sleep_level=0,
soft_cache_length=None,
soft_max_length=None,
sortish_sampler=False,
split_dataset_ratio=0.0,
steps_per_generation=None,
stop_words=[],
stopping_strategy=first_exhausted,
stream=False,
streaming=False,
strict=False,
swanlab_exp_name=None,
swanlab_lark_secret=None,
swanlab_lark_webhook_url=None,
swanlab_mode=cloud,
swanlab_project=None,
swanlab_token=<SWANLAB_TOKEN>,
swanlab_workspace=None,
sync_ref_model=False,
system=None,
target_modules=['all-linear'],
target_parameters=None,
target_regex=None,
task_type=causal_lm,
teacher_adapters=[],
teacher_model=None,
teacher_model_revision=None,
teacher_model_type=None,
temperature=0.9,
template=qwen,
template_backend=swift,
tensor_parallel_size=None,
tf32=None,
top_entropy_quantile=1.0,
top_k=50,
top_logprobs=None,
top_p=0.9,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_dtype=torch.bfloat16,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_dataloader_shuffle=True,
train_type=lora,
trainable_parameters=[],
trainable_parameters_regex=None,
truncation_strategy=delete,
tuner_backend=peft,
undesirable_weight=1.0,
use_async_engine=None,
use_chat_template=True,
use_cpu=False,
use_dora=False,
use_galore=False,
use_hf=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_logits_to_keep=None,
use_mps_device=False,
use_rslora=False,
use_swift_lora=False,
use_vllm=False,
val_dataset=['/home/ubuntu/webtest_rlhf_project/first_train_data/first_dev_rlhf.jsonl'],
val_dataset_shuffle=False,
vera_d_initial=0.1,
vera_dropout=0.0,
vera_projection_prng_key=0,
vera_rank=256,
vf_coef=0.1,
vit_gradient_checkpointing=None,
vit_lr=None,
vllm_data_parallel_size=1,
vllm_disable_custom_all_reduce=True,
vllm_enable_expert_parallel=False,
vllm_enable_prefix_caching=True,
vllm_enforce_eager=False,
vllm_gpu_memory_utilization=0.9,
vllm_limit_mm_per_prompt={},
vllm_max_lora_rank=16,
vllm_max_model_len=None,
vllm_max_num_seqs=256,
vllm_mode=colocate,
vllm_pipeline_parallel_size=1,
vllm_quantization=None,
vllm_server_base_url=None,
vllm_server_host=None,
vllm_server_port=[8000],
vllm_server_timeout=240.0,
vllm_tensor_parallel_size=1,
vllm_use_async_engine=False,
wandb_log_unique_prompts=None,
warmup_ratio=0.05,
warmup_steps=0,
weight_decay=0.1,
whiten_rewards=False,
zero_hpz_partition_size=None,
)
[INFO:swift] Downloading the model from ModelScope Hub, model_id: Qwen/Qwen-7B-Chat
[INFO:swift] Loading the model using model_dir: /home/ubuntu/.cache/modelscope/hub/models/Qwen/Qwen-7B-Chat
[INFO:swift] model_kwargs: {'device_map': None}
Downloading Model from https://www.modelscope.cn to directory: /home/ubuntu/.cache/modelscope/hub/models/Qwen/Qwen-7B-Chat
Downloading Model from https://www.modelscope.cn to directory: /home/ubuntu/.cache/modelscope/hub/models/Qwen/Qwen-7B-Chat
[2025-10-10 12:40:40,478] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-10 12:40:45,022] [INFO] [config.py:735:__init__] Config mesh_device None world_size = 1
[2025-10-10 12:40:45,023] [INFO] [comm.py:669:init_distributed] cdb=None
[2025-10-10 12:40:45,023] [INFO] [comm.py:684:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2025-10-10 12:40:46,811] [INFO] [comm.py:739:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=10.3.0.13, master_port=29500
[2025-10-10 12:40:46,812] [INFO] [comm.py:700:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Try importing flash-attention for faster inference...
Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary
Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm
Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention
[2025-10-10 12:40:48,914] [INFO] [partition_parameters.py:348:__exit__] finished initializing model - num_params = 259, num_elems = 7.72B
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:50<05:56, 50.92s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [01:44<05:15, 52.65s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [02:37<04:24, 52.81s/it]Loading checkpoint shards:  50%|█████     | 4/8 [03:28<03:27, 51.90s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [04:19<02:34, 51.51s/it]Loading checkpoint shards:  75%|███████▌  | 6/8 [05:09<01:42, 51.26s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [06:02<00:51, 51.80s/it]Loading checkpoint shards: 100%|██████████| 8/8 [06:39<00:00, 46.86s/it]Loading checkpoint shards: 100%|██████████| 8/8 [06:39<00:00, 49.88s/it]
[INFO:swift] model_info: ModelInfo(model_type='qwen', model_dir='/home/ubuntu/.cache/modelscope/hub/models/Qwen/Qwen-7B-Chat', torch_dtype=torch.bfloat16, max_model_len=8192, quant_method=None, quant_bits=None, rope_scaling=None, is_moe_model=False, config=QWenConfig {
  "architectures": [
    "QWenLMHeadModel"
  ],
  "attn_dropout_prob": 0.0,
  "auto_map": {
    "AutoConfig": "configuration_qwen.QWenConfig",
    "AutoModelForCausalLM": "modeling_qwen.QWenLMHeadModel"
  },
  "bf16": true,
  "emb_dropout_prob": 0.0,
  "fp16": false,
  "fp32": false,
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 22016,
  "kv_channels": 128,
  "layer_norm_epsilon": 1e-06,
  "max_position_embeddings": 32768,
  "model_type": "qwen",
  "no_bias": true,
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "onnx_safe": null,
  "pad_token_id": 151643,
  "rotary_emb_base": 10000,
  "rotary_pct": 1.0,
  "scale_attn_weights": true,
  "seq_length": 8192,
  "softmax_in_fp32": false,
  "tie_word_embeddings": false,
  "tokenizer_class": "QWenTokenizer",
  "torch_dtype": "bfloat16",
  "transformers_version": "4.55.4",
  "use_cache": true,
  "use_cache_kernel": false,
  "use_cache_quantization": false,
  "use_dynamic_ntk": true,
  "use_flash_attn": true,
  "use_logn_attn": true,
  "vocab_size": 151936
}
, task_type='causal_lm', num_labels=None)
[INFO:swift] model.generation_config: GenerationConfig {
  "chat_format": "chatml",
  "do_sample": true,
  "eos_token_id": 151643,
  "max_new_tokens": 512,
  "max_window_size": 24000,
  "pad_token_id": 151643,
  "temperature": 0.9,
  "top_p": 0.9
}

[INFO:swift] default_system: 'You are a helpful assistant.'
[INFO:swift] max_length: 4096
[INFO:swift] response_prefix: ''
[INFO:swift] agent_template: hermes
[INFO:swift] Start time of running main: 2025-10-10 12:47:28.026453
[INFO:swift] swift.__version__: 3.7.2
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 43 examples [00:00, 165.25 examples/s]Generating train split: 43 examples [00:00, 164.99 examples/s]
/home/ubuntu/webtest_rlhf_project/model_rlhf/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
Map:   0%|          | 0/43 [00:00<?, ? examples/s]Map: 100%|██████████| 43/43 [00:00<00:00, 3617.52 examples/s]
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 2 examples [00:00, 428.49 examples/s]
/home/ubuntu/webtest_rlhf_project/model_rlhf/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
Map:   0%|          | 0/2 [00:00<?, ? examples/s]Map: 100%|██████████| 2/2 [00:00<00:00, 473.83 examples/s]
[INFO:swift] train_dataset: Dataset({
    features: ['messages', 'label'],
    num_rows: 43
})
[INFO:swift] val_dataset: Dataset({
    features: ['messages', 'label'],
    num_rows: 2
})
Map:   0%|          | 0/43 [00:00<?, ? examples/s]Map: 100%|██████████| 43/43 [00:00<00:00, 4435.80 examples/s]
Map:   0%|          | 0/2 [00:00<?, ? examples/s]Map: 100%|██████████| 2/2 [00:00<00:00, 478.75 examples/s]
[INFO:swift] desirable_weight: 1.0, undesirable_weight: 1.0
/home/ubuntu/webtest_rlhf_project/model_rlhf/lib/python3.10/site-packages/swift/llm/train/kto.py:68: UserWarning: 
        You have different amounts of desirable/positive and undesirable/negative examples but the
        weights on the desirable and undesirable losses don't seem to be in an ideal range. Based
        on your data, we recommend EITHER desirable_weight in [0.02, '0.03]
        or undesirable_weight in [32.33, 43.0] (but NOT BOTH).
        See the documentation on how to optimally set these weights.
  warnings.warn(
Map:   0%|          | 0/43 [00:00<?, ? examples/s]Map: 100%|██████████| 43/43 [00:00<00:00, 355.05 examples/s]Map: 100%|██████████| 43/43 [00:00<00:00, 348.55 examples/s]
Map:   0%|          | 0/2 [00:00<?, ? examples/s]Map: 100%|██████████| 2/2 [00:00<00:00, 188.08 examples/s]
[INFO:swift] [CHOSEN_INPUT_IDS] [151644, 8948, 198, 56568, 110124, 107505, 9370, 103951, 81705, 105503, 1773, 112735, 108965, 21287, 19108, 26232, 81705, 11622, 26355, 3837, 118976, 100873, 104378, 43815, 36407, 101128, 103923, 102802, 33108, 104913, 3837, 101889, 100374, 56568, 32664, 103923, 108894, 101092, 105146, 104378, 43815, 43959, 85106, 9370, 81705, 11622, 26355, 3837, 85106, 101118, 81705, 11622, 26355, 100795, 26381, 3837, 99322, 102844, 100148, 43959, 105444, 9370, 81705, 11622, 26355, 3837, 100148, 100211, 100354, 151645, 198, 151644, 872, 198, 88802, 44177, 101987, 5122, 99553, 88802, 44177, 3837, 102298, 88802, 89656, 33108, 40090, 9909, 117130, 7552, 28919, 100354, 102802, 9370, 103923, 104913, 33108, 102802, 104190, 17714, 5122, 16, 21, 25, 53497, 99, 99347, 88802, 44177, 54021, 5122, 88802, 44177, 44931, 100630, 29991, 5373, 108164, 5373, 31905, 9909, 103995, 5373, 111116, 5373, 103960, 64359, 107989, 60548, 20450, 130957, 110045, 44091, 3837, 103960, 21515, 88802, 102298, 104027, 103190, 37641, 16, 22, 25, 53497, 99, 99347, 88802, 74193, 60548, 44177, 5122, 54021, 101903, 38342, 60548, 105595, 88802, 37641, 16, 23, 25, 53497, 99, 99347, 88802, 110045, 44177, 5122, 54021, 101903, 110045, 105595, 88802, 3837, 59879, 60548, 20450, 99805, 32044, 108467, 9909, 104027, 60548, 9370, 18493, 31235, 104135, 7552, 37641, 16, 24, 25, 220, 38342, 60548, 103960, 88802, 89656, 5122, 103960, 21515, 88802, 101041, 54021, 112516, 20742, 23990, 37641, 17, 16, 25, 220, 38342, 60548, 111116, 88802, 89656, 5122, 111116, 21515, 88802, 18493, 111446, 100649, 111116, 82237, 115199, 3837, 72651, 104089, 111116, 89656, 37641, 17, 17, 25, 83002, 110, 60548, 103960, 88802, 89656, 5122, 54021, 103190, 5373, 110045, 9370, 106367, 5373, 50404, 111230, 81217, 88991, 102349, 3837, 99553, 12881, 87256, 77598, 107060, 10429, 84184, 9909, 70361, 112516, 3837, 60548, 24562, 16530, 50007, 103190, 7552, 37641, 17, 18, 25, 83002, 110, 60548, 103995, 88802, 89656, 5122, 54021, 103995, 82237, 115199, 3837, 72651, 104089, 103995, 89656, 37641, 17, 19, 25, 83002, 110, 60548, 111116, 88802, 89656, 5122, 54021, 111116, 82237, 115199, 3837, 72651, 104089, 111116, 89656, 37641, 21, 20, 25, 53040, 100104, 44177, 39352, 5122, 54021, 21894, 100008, 55338, 111116, 44177, 3837, 44931, 100630, 111116, 29991, 5373, 111116, 102335, 3837, 40090, 100630, 117130, 5373, 57019, 5373, 100085, 11622, 14, 111456, 37641, 22, 16, 25, 34369, 101, 42223, 88802, 44177, 39352, 5122, 54021, 88802, 44177, 3837, 44931, 100630, 88802, 29991, 5373, 88802, 108164, 5373, 88802, 31905, 5373, 44091, 5373, 72017, 20450, 5373, 101882, 60548, 20450, 5373, 60548, 99559, 3837, 40090, 100630, 117130, 37641, 22, 17, 25, 220, 88802, 89656, 100111, 5122, 100111, 88802, 100700, 27369, 3837, 100630, 110045, 88802, 100787, 9909, 59879, 101065, 33108, 105256, 108788, 101903, 60548, 99559, 74276, 151645, 198, 151644, 77091, 198, 104210, 100354, 101042, 3837, 43959, 87752, 98380, 81705, 11622, 26355, 48443, 334, 18, 15, 62, 10904, 107109, 10958, 100134, 88802, 44177, 62, 74193, 60548, 8582, 1019, 12, 220, 104747, 52334, 5122, 47, 15, 198, 12, 4891, 231, 235, 21596, 76095, 5122, 47606, 38342, 60548, 105595, 88802, 198, 12, 6567, 36548, 105652, 5122, 16, 13, 72651, 100134, 88802, 106393, 26, 17, 13, 47363, 101040, 74193, 60548, 8582, 198, 12, 18137, 95, 226, 22704, 59151, 5122, 16, 13, 54021, 101903, 38342, 60548, 105595, 88802, 44177, 26, 17, 13, 44931, 102298, 5122, 29991, 5373, 108164, 5373, 31905, 9909, 103995, 5373, 111116, 5373, 103960, 64359, 107989, 60548, 20450, 26, 18, 13, 103960, 21515, 88802, 54021, 104027, 103190, 26, 19, 13, 59879, 107989, 20450, 99294, 32044, 108467, 271, 334, 15, 17, 62, 10904, 39352, 78882, 10958, 108905, 88802, 44177, 101987, 1019, 12, 220, 104747, 52334, 5122, 47, 16, 198, 12, 4891, 231, 235, 21596, 76095, 5122, 47606, 108905, 88802, 20074, 198, 12, 6567, 36548, 105652, 5122, 16, 13, 101040, 108905, 88802, 39352, 26, 17, 13, 100111, 88802, 44177, 198, 12, 18137, 95, 226, 22704, 59151, 5122, 16, 13, 54021, 44931, 5122, 113280, 29991, 5373, 88802, 31905, 5373, 72017, 20450, 5373, 101882, 60548, 20450, 5373, 60548, 99559, 5373, 44091, 5373, 40090, 26, 17, 13, 100143, 117130, 40090, 26, 18, 13, 104988, 100873, 102188, 26, 19, 13, 88802, 31905, 106281, 103960, 151645]
[INFO:swift] [CHOSEN_INPUT] <|im_start|>system
你是一名资深的软件测试工程师。你需要帮我生成功能测试用例，需要用完整的需求内容来理解业务关联和逻辑，然后结合你对业务的理解针对指定的需求内容生成需要的测试用例，需要考虑测试用例覆盖度，切忌不要生成重复的测试用例，不要创造需求<|im_end|>
<|im_start|>user
任务列表展示：提供任务列表，包含任务详情和操作（查看详情）。。需求关联的业务逻辑和关联规则为：16: 学习任务列表显示：任务列表字段包括名称、要点、类型（课程、文档、考试）、剩余完成时间｜已完成状态，考试类任务包含最新分数。，17: 学习任务待完成列表：显示员工未完成的学习任务。，18: 学习任务已完成列表：显示员工已完成的学习任务，按完成时间倒序排列（最新完成的在最上面）。，19: 未完成考试任务详情：考试类任务直接显示答题表单。，21: 未完成文档任务详情：文档类任务在顶部增加文档链接卡片，点击打开文档详情。，22: 已完成考试任务详情：显示分数、已完成的题目、选择的答案及正确答案，提供「再考一遍」按钮（重新答题，完成前不更新分数）。，23: 已完成课程任务详情：显示课程链接卡片，点击打开课程详情。，24: 已完成文档任务详情：显示文档链接卡片，点击打开文档详情。，65: 文档列表管理：显示本机构所有文档列表，字段包括文档名称、文档简介，操作包括查看详情、编辑、禁用/启用。，71: 全员任务列表管理：显示任务列表，字段包括任务名称、任务要点、任务类型、状态、发送时间、要求完成时间、完成情况，操作包括查看详情。，72: 任务详情查看：查看任务详细信息，包括已完成任务统计（按区域和门店汇总员工完成情况）。<|im_end|>
<|im_start|>assistant
基于需求分析，生成以下功能测试用例：

**30_【小程序】学习任务列表_待完成Tab**
- 优先级：P0
- 前置条件：存在未完成的学习任务
- 操作步骤：1.点击学习任务模块;2.默认进入待完成Tab
- 预期结果：1.显示员工未完成的学习任务列表;2.字段包含：名称、要点、类型（课程、文档、考试）、剩余完成时间;3.考试类任务显示最新分数;4.按剩余时间升序排列

**02_【管理端】全员任务列表展示**
- 优先级：P1
- 前置条件：存在全员任务数据
- 操作步骤：1.进入全员任务管理;2.查看任务列表
- 预期结果：1.显示字段：试题名称、任务类型、发送时间、要求完成时间、完成情况、状态、操作;2.支持查看详情操作;3.数据显示完整准确;4.任务类型均为考试<|im_end|>
[INFO:swift] [CHOSEN_LABELS_IDS] [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 104210, 100354, 101042, 3837, 43959, 87752, 98380, 81705, 11622, 26355, 48443, 334, 18, 15, 62, 10904, 107109, 10958, 100134, 88802, 44177, 62, 74193, 60548, 8582, 1019, 12, 220, 104747, 52334, 5122, 47, 15, 198, 12, 4891, 231, 235, 21596, 76095, 5122, 47606, 38342, 60548, 105595, 88802, 198, 12, 6567, 36548, 105652, 5122, 16, 13, 72651, 100134, 88802, 106393, 26, 17, 13, 47363, 101040, 74193, 60548, 8582, 198, 12, 18137, 95, 226, 22704, 59151, 5122, 16, 13, 54021, 101903, 38342, 60548, 105595, 88802, 44177, 26, 17, 13, 44931, 102298, 5122, 29991, 5373, 108164, 5373, 31905, 9909, 103995, 5373, 111116, 5373, 103960, 64359, 107989, 60548, 20450, 26, 18, 13, 103960, 21515, 88802, 54021, 104027, 103190, 26, 19, 13, 59879, 107989, 20450, 99294, 32044, 108467, 271, 334, 15, 17, 62, 10904, 39352, 78882, 10958, 108905, 88802, 44177, 101987, 1019, 12, 220, 104747, 52334, 5122, 47, 16, 198, 12, 4891, 231, 235, 21596, 76095, 5122, 47606, 108905, 88802, 20074, 198, 12, 6567, 36548, 105652, 5122, 16, 13, 101040, 108905, 88802, 39352, 26, 17, 13, 100111, 88802, 44177, 198, 12, 18137, 95, 226, 22704, 59151, 5122, 16, 13, 54021, 44931, 5122, 113280, 29991, 5373, 88802, 31905, 5373, 72017, 20450, 5373, 101882, 60548, 20450, 5373, 60548, 99559, 5373, 44091, 5373, 40090, 26, 17, 13, 100143, 117130, 40090, 26, 18, 13, 104988, 100873, 102188, 26, 19, 13, 88802, 31905, 106281, 103960, 151645]
[INFO:swift] [CHOSEN_LABELS] [-100 * 422]基于需求分析，生成以下功能测试用例：

**30_【小程序】学习任务列表_待完成Tab**
- 优先级：P0
- 前置条件：存在未完成的学习任务
- 操作步骤：1.点击学习任务模块;2.默认进入待完成Tab
- 预期结果：1.显示员工未完成的学习任务列表;2.字段包含：名称、要点、类型（课程、文档、考试）、剩余完成时间;3.考试类任务显示最新分数;4.按剩余时间升序排列

**02_【管理端】全员任务列表展示**
- 优先级：P1
- 前置条件：存在全员任务数据
- 操作步骤：1.进入全员任务管理;2.查看任务列表
- 预期结果：1.显示字段：试题名称、任务类型、发送时间、要求完成时间、完成情况、状态、操作;2.支持查看详情操作;3.数据显示完整准确;4.任务类型均为考试<|im_end|>
[INFO:swift] [REJECTED_INPUT_IDS] [151644, 8948, 198, 56568, 110124, 107505, 9370, 103951, 81705, 105503, 1773, 112735, 108965, 21287, 19108, 26232, 81705, 11622, 26355, 3837, 118976, 100873, 104378, 43815, 36407, 101128, 103923, 102802, 33108, 104913, 3837, 101889, 100374, 56568, 32664, 103923, 108894, 101092, 105146, 104378, 43815, 43959, 85106, 9370, 81705, 11622, 26355, 3837, 85106, 101118, 81705, 11622, 26355, 100795, 26381, 3837, 99322, 102844, 100148, 43959, 105444, 9370, 81705, 11622, 26355, 3837, 100148, 100211, 100354, 151645, 198, 151644, 872, 198, 88802, 44177, 101987, 5122, 99553, 88802, 44177, 3837, 102298, 88802, 89656, 33108, 40090, 9909, 117130, 7552, 28919, 100354, 102802, 9370, 103923, 104913, 33108, 102802, 104190, 17714, 5122, 16, 21, 25, 53497, 99, 99347, 88802, 44177, 54021, 5122, 88802, 44177, 44931, 100630, 29991, 5373, 108164, 5373, 31905, 9909, 103995, 5373, 111116, 5373, 103960, 64359, 107989, 60548, 20450, 130957, 110045, 44091, 3837, 103960, 21515, 88802, 102298, 104027, 103190, 37641, 16, 22, 25, 53497, 99, 99347, 88802, 74193, 60548, 44177, 5122, 54021, 101903, 38342, 60548, 105595, 88802, 37641, 16, 23, 25, 53497, 99, 99347, 88802, 110045, 44177, 5122, 54021, 101903, 110045, 105595, 88802, 3837, 59879, 60548, 20450, 99805, 32044, 108467, 9909, 104027, 60548, 9370, 18493, 31235, 104135, 7552, 37641, 16, 24, 25, 220, 38342, 60548, 103960, 88802, 89656, 5122, 103960, 21515, 88802, 101041, 54021, 112516, 20742, 23990, 37641, 17, 16, 25, 220, 38342, 60548, 111116, 88802, 89656, 5122, 111116, 21515, 88802, 18493, 111446, 100649, 111116, 82237, 115199, 3837, 72651, 104089, 111116, 89656, 37641, 17, 17, 25, 83002, 110, 60548, 103960, 88802, 89656, 5122, 54021, 103190, 5373, 110045, 9370, 106367, 5373, 50404, 111230, 81217, 88991, 102349, 3837, 99553, 12881, 87256, 77598, 107060, 10429, 84184, 9909, 70361, 112516, 3837, 60548, 24562, 16530, 50007, 103190, 7552, 37641, 17, 18, 25, 83002, 110, 60548, 103995, 88802, 89656, 5122, 54021, 103995, 82237, 115199, 3837, 72651, 104089, 103995, 89656, 37641, 17, 19, 25, 83002, 110, 60548, 111116, 88802, 89656, 5122, 54021, 111116, 82237, 115199, 3837, 72651, 104089, 111116, 89656, 37641, 21, 20, 25, 53040, 100104, 44177, 39352, 5122, 54021, 21894, 100008, 55338, 111116, 44177, 3837, 44931, 100630, 111116, 29991, 5373, 111116, 102335, 3837, 40090, 100630, 117130, 5373, 57019, 5373, 100085, 11622, 14, 111456, 37641, 22, 16, 25, 34369, 101, 42223, 88802, 44177, 39352, 5122, 54021, 88802, 44177, 3837, 44931, 100630, 88802, 29991, 5373, 88802, 108164, 5373, 88802, 31905, 5373, 44091, 5373, 72017, 20450, 5373, 101882, 60548, 20450, 5373, 60548, 99559, 3837, 40090, 100630, 117130, 37641, 22, 17, 25, 220, 88802, 89656, 100111, 5122, 100111, 88802, 100700, 27369, 3837, 100630, 110045, 88802, 100787, 9909, 59879, 101065, 33108, 105256, 108788, 101903, 60548, 99559, 74276, 151645, 198, 151644, 77091, 198, 104210, 100354, 101042, 3837, 43959, 87752, 98380, 81705, 11622, 26355, 48443, 334, 15, 18, 62, 10904, 39352, 78882, 10958, 107973, 88802, 62, 99896, 27369, 107354, 1019, 12, 220, 104747, 52334, 5122, 47, 15, 198, 12, 4891, 231, 235, 21596, 76095, 5122, 50377, 103960, 88802, 198, 12, 6567, 36548, 105652, 5122, 16, 13, 72651, 6, 107973, 88802, 6, 84184, 26, 17, 13, 107354, 88802, 99896, 27369, 198, 12, 18137, 95, 226, 22704, 59151, 5122, 16, 13, 100080, 20221, 107973, 88802, 20742, 23990, 26, 17, 13, 102298, 44931, 5122, 88802, 101121, 5373, 101065, 5373, 101882, 60548, 20450, 5373, 113280, 50404, 26, 18, 13, 58514, 68756, 44931, 99307, 41362, 26, 19, 13, 44931, 68805, 99307, 41362, 271, 334, 15, 22, 62, 10904, 39352, 78882, 10958, 107973, 88802, 62, 60548, 20450, 43918, 1019, 12, 220, 104747, 52334, 5122, 47, 15, 198, 12, 4891, 231, 235, 21596, 76095, 5122, 18493, 107973, 88802, 36295, 198, 12, 6567, 36548, 105652, 5122, 16, 13, 43918, 101882, 60548, 20450, 26, 17, 13, 50404, 101970, 20450, 198, 12, 18137, 95, 226, 22704, 59151, 5122, 16, 13, 100143, 45785, 20450, 50404, 31548, 26, 17, 13, 110263, 50404, 100688, 20450, 26, 18, 13, 20450, 68805, 88991, 26, 19, 13, 57218, 67949, 20450, 104877, 100745, 151645]
[INFO:swift] [REJECTED_INPUT] <|im_start|>system
你是一名资深的软件测试工程师。你需要帮我生成功能测试用例，需要用完整的需求内容来理解业务关联和逻辑，然后结合你对业务的理解针对指定的需求内容生成需要的测试用例，需要考虑测试用例覆盖度，切忌不要生成重复的测试用例，不要创造需求<|im_end|>
<|im_start|>user
任务列表展示：提供任务列表，包含任务详情和操作（查看详情）。。需求关联的业务逻辑和关联规则为：16: 学习任务列表显示：任务列表字段包括名称、要点、类型（课程、文档、考试）、剩余完成时间｜已完成状态，考试类任务包含最新分数。，17: 学习任务待完成列表：显示员工未完成的学习任务。，18: 学习任务已完成列表：显示员工已完成的学习任务，按完成时间倒序排列（最新完成的在最上面）。，19: 未完成考试任务详情：考试类任务直接显示答题表单。，21: 未完成文档任务详情：文档类任务在顶部增加文档链接卡片，点击打开文档详情。，22: 已完成考试任务详情：显示分数、已完成的题目、选择的答案及正确答案，提供「再考一遍」按钮（重新答题，完成前不更新分数）。，23: 已完成课程任务详情：显示课程链接卡片，点击打开课程详情。，24: 已完成文档任务详情：显示文档链接卡片，点击打开文档详情。，65: 文档列表管理：显示本机构所有文档列表，字段包括文档名称、文档简介，操作包括查看详情、编辑、禁用/启用。，71: 全员任务列表管理：显示任务列表，字段包括任务名称、任务要点、任务类型、状态、发送时间、要求完成时间、完成情况，操作包括查看详情。，72: 任务详情查看：查看任务详细信息，包括已完成任务统计（按区域和门店汇总员工完成情况）。<|im_end|>
<|im_start|>assistant
基于需求分析，生成以下功能测试用例：

**03_【管理端】下发任务_基础信息填写**
- 优先级：P0
- 前置条件：创建考试任务
- 操作步骤：1.点击'下发任务'按钮;2.填写任务基础信息
- 预期结果：1.弹出下发任务表单;2.包含字段：任务范围、区域、要求完成时间、试题选择;3.必填字段校验;4.字段格式校验

**07_【管理端】下发任务_完成时间设置**
- 优先级：P0
- 前置条件：在下发任务页面
- 操作步骤：1.设置要求完成时间;2.选择不同的时间
- 预期结果：1.支持日期时间选择器;2.不允许选择过去时间;3.时间格式正确;4.与当前时间对比合理<|im_end|>
[INFO:swift] [REJECTED_LABELS_IDS] [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 104210, 100354, 101042, 3837, 43959, 87752, 98380, 81705, 11622, 26355, 48443, 334, 15, 18, 62, 10904, 39352, 78882, 10958, 107973, 88802, 62, 99896, 27369, 107354, 1019, 12, 220, 104747, 52334, 5122, 47, 15, 198, 12, 4891, 231, 235, 21596, 76095, 5122, 50377, 103960, 88802, 198, 12, 6567, 36548, 105652, 5122, 16, 13, 72651, 6, 107973, 88802, 6, 84184, 26, 17, 13, 107354, 88802, 99896, 27369, 198, 12, 18137, 95, 226, 22704, 59151, 5122, 16, 13, 100080, 20221, 107973, 88802, 20742, 23990, 26, 17, 13, 102298, 44931, 5122, 88802, 101121, 5373, 101065, 5373, 101882, 60548, 20450, 5373, 113280, 50404, 26, 18, 13, 58514, 68756, 44931, 99307, 41362, 26, 19, 13, 44931, 68805, 99307, 41362, 271, 334, 15, 22, 62, 10904, 39352, 78882, 10958, 107973, 88802, 62, 60548, 20450, 43918, 1019, 12, 220, 104747, 52334, 5122, 47, 15, 198, 12, 4891, 231, 235, 21596, 76095, 5122, 18493, 107973, 88802, 36295, 198, 12, 6567, 36548, 105652, 5122, 16, 13, 43918, 101882, 60548, 20450, 26, 17, 13, 50404, 101970, 20450, 198, 12, 18137, 95, 226, 22704, 59151, 5122, 16, 13, 100143, 45785, 20450, 50404, 31548, 26, 17, 13, 110263, 50404, 100688, 20450, 26, 18, 13, 20450, 68805, 88991, 26, 19, 13, 57218, 67949, 20450, 104877, 100745, 151645]
[INFO:swift] [REJECTED_LABELS] [-100 * 422]基于需求分析，生成以下功能测试用例：

**03_【管理端】下发任务_基础信息填写**
- 优先级：P0
- 前置条件：创建考试任务
- 操作步骤：1.点击'下发任务'按钮;2.填写任务基础信息
- 预期结果：1.弹出下发任务表单;2.包含字段：任务范围、区域、要求完成时间、试题选择;3.必填字段校验;4.字段格式校验

**07_【管理端】下发任务_完成时间设置**
- 优先级：P0
- 前置条件：在下发任务页面
- 操作步骤：1.设置要求完成时间;2.选择不同的时间
- 预期结果：1.支持日期时间选择器;2.不允许选择过去时间;3.时间格式正确;4.与当前时间对比合理<|im_end|>
[INFO:swift] Dataset Token Length: 498.837209±89.486112, min=343.000000, max=702.000000, size=43
[INFO:swift] Dataset Token Length: 386.500000±35.500000, min=351.000000, max=422.000000, size=2
[INFO:swift] The RLHFArguments will be saved in: /home/ubuntu/webtest_rlhf_project/first_rlhf_model_output/v0-20251010-124038/args.json
[INFO:swift] lora_config: LoraConfig(task_type='CAUSAL_LM', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='/home/ubuntu/.cache/modelscope/hub/models/Qwen/Qwen-7B-Chat', revision=None, inference_mode=False, r=8, target_modules={'c_attn', 'c_proj', 'w2', 'w1'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=[], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, eva_config=None, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False, lora_dtype=None, lorap_lr_ratio=None, lorap_emb_lr=1e-06)
[INFO:swift] model: PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): QWenLMHeadModel(
      (transformer): QWenModel(
        (wte): Embedding(151936, 4096)
        (drop): Dropout(p=0.0, inplace=False)
        (rotary_emb): RotaryEmbedding()
        (h): ModuleList(
          (0-31): 32 x QWenBlock(
            (ln_1): RMSNorm()
            (attn): QWenAttention(
              (c_attn): lora.Linear(
                (base_layer): Linear(in_features=4096, out_features=12288, bias=True)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=8, out_features=12288, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (c_proj): lora.Linear(
                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=8, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (attn_dropout): Dropout(p=0.0, inplace=False)
            )
            (ln_2): RMSNorm()
            (mlp): QWenMLP(
              (w1): lora.Linear(
                (base_layer): Linear(in_features=4096, out_features=11008, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=8, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (w2): lora.Linear(
                (base_layer): Linear(in_features=4096, out_features=11008, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=8, out_features=11008, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (c_proj): lora.Linear(
                (base_layer): Linear(in_features=11008, out_features=4096, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=11008, out_features=8, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=8, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
            )
          )
        )
        (ln_f): RMSNorm()
      )
      (lm_head): Linear(in_features=4096, out_features=151936, bias=False)
    )
  )
)
[INFO:swift] model_parameter_info: PeftModelForCausalLM: 7739.2159M Params (17.8913M Trainable [0.2312%]), 1.0486M Buffers.
/home/ubuntu/webtest_rlhf_project/model_rlhf/lib/python3.10/site-packages/swift/trainers/mixin.py:94: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `KTOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(
[INFO:swift] use_reentrant: True
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
[INFO:swift] The logging file will be saved in: /home/ubuntu/webtest_rlhf_project/first_rlhf_model_output/v0-20251010-124038/logging.jsonl
You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.
Gradient accumulation steps mismatch: GradientAccumulationPlugin has 1, DeepSpeed config has 16. Using DeepSpeed's value.
Parameter Offload: Total persistent parameters: 6950912 in 289 params
Train:   0%|          | 0/9 [00:00<?, ?it/s]/home/ubuntu/webtest_rlhf_project/model_rlhf/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Train:  11%|█         | 1/9 [01:52<15:01, 112.69s/it]                                                     Train:  11%|█         | 1/9 [01:52<15:01, 112.69s/it]Train:  11%|█         | 1/9 [01:52<15:01, 112.69s/it]Train:  22%|██▏       | 2/9 [03:39<12:45, 109.38s/it]                                                     Train:  22%|██▏       | 2/9 [03:39<12:45, 109.38s/it]Train:  22%|██▏       | 2/9 [03:39<12:45, 109.38s/it]Train:  33%|███▎      | 3/9 [04:57<09:28, 94.75s/it] {'loss': 0.5, 'grad_norm': 5.29074511, 'learning_rate': 3e-05, 'memory(GiB)': 16.03, 'train_speed(iter/s)': 0.008556, 'rewards/chosen': 0.0, 'logps/chosen': -361.25, 'logits/chosen': -257753088.0, 'kl': 0.0, 'epoch': 0.37, 'global_step/max_steps': '1/9', 'percentage': '11.11%', 'elapsed_time': '1m 52s', 'remaining_time': '15m 1s'}
{'loss': 0.5, 'grad_norm': 5.12070264, 'learning_rate': 2.886e-05, 'memory(GiB)': 16.03, 'train_speed(iter/s)': 0.008931, 'rewards/chosen': 0.0, 'logps/chosen': -349.375, 'logits/chosen': -245694464.0, 'kl': 0.0, 'epoch': 0.74, 'global_step/max_steps': '2/9', 'percentage': '22.22%', 'elapsed_time': '3m 39s', 'remaining_time': '12m 49s'}

Val:   0%|          | 0/2 [00:00<?, ?it/s]Val: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]                                                                                                      Train:  33%|███▎      | 3/9 [05:04<09:28, 94.75s/it]Val: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]Train:  33%|███▎      | 3/9 [05:04<09:28, 94.75s/it]Val: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
[INFO:swift] Saving model checkpoint to /home/ubuntu/webtest_rlhf_project/first_rlhf_model_output/v0-20251010-124038/checkpoint-3
{'eval_loss': 0.52539062, 'eval_runtime': 7.7067, 'eval_samples_per_second': 0.26, 'eval_steps_per_second': 0.26, 'eval_rewards/chosen': 0.40039062, 'eval_logps/chosen': -288.0, 'eval_logits/chosen': -191365120.0, 'eval_kl': 5.0, 'epoch': 1.0, 'global_step/max_steps': '3/9', 'percentage': '33.33%', 'elapsed_time': '5m 4s', 'remaining_time': '10m 9s'}
/home/ubuntu/webtest_rlhf_project/model_rlhf/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Train:  44%|████▍     | 4/9 [06:55<08:41, 104.21s/it]                                                     Train:  44%|████▍     | 4/9 [06:55<08:41, 104.21s/it]Train:  44%|████▍     | 4/9 [06:55<08:41, 104.21s/it]Train:  56%|█████▌    | 5/9 [08:43<07:01, 105.31s/it]Train:  67%|██████▋   | 6/9 [10:00<04:47, 95.89s/it]                                                     Train:  67%|██████▋   | 6/9 [10:00<04:47, 95.89s/it]Train:  67%|██████▋   | 6/9 [10:00<04:47, 95.89s/it]{'loss': 0.50217509, 'grad_norm': 5.38406371, 'learning_rate': 2.074e-05, 'memory(GiB)': 19.91, 'train_speed(iter/s)': 0.009524, 'rewards/chosen': 0.36360677, 'logps/chosen': -371.25925926, 'logits/chosen': -262066327.7037037, 'kl': 3.66666675, 'epoch': 1.37, 'global_step/max_steps': '4/9', 'percentage': '44.44%', 'elapsed_time': '6m 55s', 'remaining_time': '8m 39s'}
{'loss': 0.49789152, 'grad_norm': 6.06096186, 'learning_rate': 9.26e-06, 'memory(GiB)': 19.91, 'train_speed(iter/s)': 0.00992, 'rewards/chosen': 1.19690394, 'logps/chosen': -355.88888889, 'logits/chosen': -254881640.2962963, 'kl': 11.85185146, 'epoch': 2.0, 'global_step/max_steps': '6/9', 'percentage': '66.67%', 'elapsed_time': '10m 0s', 'remaining_time': '5m 0s'}

Val:   0%|          | 0/2 [00:00<?, ?it/s]Val: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]                                                                                                      Train:  67%|██████▋   | 6/9 [10:08<04:47, 95.89s/it]Val: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]Train:  67%|██████▋   | 6/9 [10:08<04:47, 95.89s/it]Val: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
/home/ubuntu/webtest_rlhf_project/model_rlhf/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[INFO:swift] Saving model checkpoint to /home/ubuntu/webtest_rlhf_project/first_rlhf_model_output/v0-20251010-124038/checkpoint-6
{'eval_loss': 0.5, 'eval_runtime': 7.6715, 'eval_samples_per_second': 0.261, 'eval_steps_per_second': 0.261, 'eval_rewards/chosen': 1.69921875, 'eval_logps/chosen': -275.0, 'eval_logits/chosen': -191365120.0, 'eval_kl': 17.0, 'epoch': 2.0, 'global_step/max_steps': '6/9', 'percentage': '66.67%', 'elapsed_time': '10m 8s', 'remaining_time': '5m 4s'}
/home/ubuntu/webtest_rlhf_project/model_rlhf/lib/python3.10/site-packages/torch/utils/checkpoint.py:86: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
Train:  78%|███████▊  | 7/9 [11:59<03:26, 103.29s/it]Train:  89%|████████▉ | 8/9 [13:46<01:44, 104.58s/it]                                                     Train:  89%|████████▉ | 8/9 [13:46<01:44, 104.58s/it]Train:  89%|████████▉ | 8/9 [13:46<01:44, 104.58s/it]Train: 100%|██████████| 9/9 [15:03<00:00, 96.04s/it] {'loss': 0.49169922, 'grad_norm': 5.62081998, 'learning_rate': 1.14e-06, 'memory(GiB)': 19.91, 'train_speed(iter/s)': 0.00963, 'rewards/chosen': 1.96899414, 'logps/chosen': -335.625, 'logits/chosen': -251461632.0, 'kl': 19.34375, 'epoch': 2.74, 'global_step/max_steps': '8/9', 'percentage': '88.89%', 'elapsed_time': '13m 46s', 'remaining_time': '1m 43s'}

Val:   0%|          | 0/2 [00:00<?, ?it/s]Val: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]                                                                                                      Train: 100%|██████████| 9/9 [15:11<00:00, 96.04s/it]Val: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]Train: 100%|██████████| 9/9 [15:11<00:00, 96.04s/it]Val: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]
/home/ubuntu/webtest_rlhf_project/model_rlhf/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4631: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[INFO:swift] Saving model checkpoint to /home/ubuntu/webtest_rlhf_project/first_rlhf_model_output/v0-20251010-124038/checkpoint-9
                                                    Train: 100%|██████████| 9/9 [15:12<00:00, 96.04s/it]Train: 100%|██████████| 9/9 [15:12<00:00, 96.04s/it]Train: 100%|██████████| 9/9 [15:12<00:00, 101.39s/it]
[INFO:swift] last_model_checkpoint: /home/ubuntu/webtest_rlhf_project/first_rlhf_model_output/v0-20251010-124038/checkpoint-9
[INFO:swift] best_model_checkpoint: /home/ubuntu/webtest_rlhf_project/first_rlhf_model_output/v0-20251010-124038/checkpoint-6
[INFO:swift] images_dir: /home/ubuntu/webtest_rlhf_project/first_rlhf_model_output/v0-20251010-124038/images
[INFO:swift] End time of running main: 2025-10-10 13:02:59.796407
{'eval_loss': 0.52539062, 'eval_runtime': 7.7185, 'eval_samples_per_second': 0.259, 'eval_steps_per_second': 0.259, 'eval_rewards/chosen': 2.1015625, 'eval_logps/chosen': -271.0, 'eval_logits/chosen': -191365120.0, 'eval_kl': 22.0, 'epoch': 3.0, 'global_step/max_steps': '9/9', 'percentage': '100.00%', 'elapsed_time': '15m 11s', 'remaining_time': '0s'}
{'train_runtime': 912.556, 'train_samples_per_second': 0.141, 'train_steps_per_second': 0.01, 'train_loss': 0.49868313, 'epoch': 3.0, 'global_step/max_steps': '9/9', 'percentage': '100.00%', 'elapsed_time': '15m 12s', 'remaining_time': '0s'}
